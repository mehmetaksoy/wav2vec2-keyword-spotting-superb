{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUzThp4XmH7_"
      },
      "outputs": [],
      "source": [
        "# Hücre 1: Gerekli Kütüphanelerin Kurulumu (Wav2Vec2 için)\n",
        "\n",
        "# Lütfen bu hücreyi çalıştırmadan önce, eğer yeni bir not defteri değilse,\n",
        "# Colab çalışma zamanını \"Disconnect and delete runtime\" ile sıfırlamanız önerilir.\n",
        "# Eğer yeni bir not defteri ise doğrudan çalıştırabilirsiniz.\n",
        "\n",
        "print(\"Wav2Vec2 projesi için gerekli kütüphaneler kuruluyor...\")\n",
        "\n",
        "# 1. Başarılı BERT projesindeki stabil versiyonları hedefleyelim:\n",
        "#    NumPy'ye dokunmuyoruz, Colab'ın varsayılanını kullanacağız.\n",
        "#    Pandas'a dokunmuyoruz, Colab'ın varsayılanını kullanacağız.\n",
        "\n",
        "# Datasets ve Transformers için bilinen iyi versiyonlar:\n",
        "!pip install datasets==3.6.0 -q\n",
        "print(\"Datasets 3.6.0 kuruldu.\")\n",
        "\n",
        "!pip install transformers==4.48.3 -q\n",
        "print(\"Transformers 4.48.3 kuruldu.\")\n",
        "\n",
        "# 2. Ses işleme kütüphaneleri:\n",
        "# torchaudio genellikle PyTorch ile uyumlu gelir, versiyon belirtmeden deneyelim.\n",
        "# Colab'da PyTorch genellikle önceden kuruludur.\n",
        "# Eğer PyTorch'unuzla uyumsuzluk olursa, PyTorch versiyonunuza uygun bir torchaudio kurmanız gerekebilir.\n",
        "!pip install torchaudio -q\n",
        "print(\"torchaudio kuruldu/güncellendi.\")\n",
        "\n",
        "!pip install librosa -q\n",
        "print(\"librosa kuruldu/güncellendi.\")\n",
        "\n",
        "# 3. Diğer yardımcı kütüphaneler\n",
        "!pip install scikit-learn matplotlib seaborn -q\n",
        "print(\"Scikit-learn, Matplotlib, Seaborn kuruldu/güncellendi.\")\n",
        "\n",
        "print(\"\\nKütüphane kurulumları (Hücre 1) tamamlandı.\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "print(\"!!! LÜTFEN ŞİMDİ Colab Çalışma Zamanını (Runtime -> Restart runtime)      !!!\")\n",
        "print(\"!!! KESİNLİKLE YENİDEN BAŞLATIN. Bu, kurulumların oturmasını sağlar.         !!!\")\n",
        "print(\"!!! Yeniden başlattıktan sonra Hücre 1'i TEKRAR ÇALIŞTIRMAYIN,           !!!\")\n",
        "print(\"!!! doğrudan Hücre 2'ye (Kütüphane Importları) geçin.                   !!!\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 2: Kütüphanelerin Import Edilmesi, Versiyon Kontrolü ve Cihaz Belirleme (Wav2Vec2 için)\n",
        "\n",
        "# Temel ve Hugging Face kütüphanelerinin import edilmesi\n",
        "import transformers\n",
        "import datasets\n",
        "import torch\n",
        "import torchaudio # Ses işleme için PyTorch kütüphanesi\n",
        "import librosa    # Ses analizi ve işleme için\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn # scikit-learn'ün ana modülü\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import sys    # Python versiyonunu almak için\n",
        "import time   # Süre ölçümleri için\n",
        "\n",
        "# Hugging Face kütüphanelerinden sık kullanılacak modüller (ilerleyen aşamalarda)\n",
        "# from datasets import load_dataset # Zaten yukarıda var\n",
        "# from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Cihazı belirleme: GPU varsa GPU, yoksa CPU kullanılacak.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# İsteğe bağlı: Daha temiz bir çıktı için uyarıları bastırma\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"Kütüphaneler başarıyla import edildi.\")\n",
        "print(\"-\" * 50)\n",
        "print(\"KULLANILAN KÜTÜPHANE VERSİYONLARI:\")\n",
        "print(f\"  Python Versiyonu (sys.version): {sys.version.split()[0]}\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "if hasattr(torchaudio, '__version__'): # torchaudio bazen __version__ göstermeyebilir\n",
        "    print(f\"  Torchaudio: {torchaudio.__version__}\")\n",
        "else:\n",
        "    print(\"  Torchaudio: Versiyon bilgisi alınamadı (ama import edildi).\")\n",
        "print(f\"  Librosa: {librosa.__version__}\")\n",
        "print(f\"  Transformers: {transformers.__version__}\")\n",
        "print(f\"  Datasets: {datasets.__version__}\")\n",
        "print(f\"  Numpy: {np.__version__}\")\n",
        "print(f\"  Pandas: {pd.__version__}\")\n",
        "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"  Matplotlib: {matplotlib.__version__}\")\n",
        "print(f\"  Seaborn: {sns.__version__}\")\n",
        "# fsspec gibi alt bağımlılıkları da isterseniz yazdırabiliriz ama şimdilik bunlar yeterli.\n",
        "print(\"-\" * 50)\n",
        "print(f\"KULLANILACAK CİHAZ: {device}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(f\"  CUDA Versiyonu (torch.version.cuda): {torch.version.cuda}\")\n",
        "    print(f\"  cuDNN Versiyonu (torch.backends.cudnn.version()): {torch.backends.cudnn.version()}\")\n",
        "    print(f\"  Kullanılabilir GPU Sayısı: {torch.cuda.device_count()}\")\n",
        "    if torch.cuda.device_count() > 0:\n",
        "        print(f\"  Aktif GPU Adı: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"-\" * 50)\n",
        "else:\n",
        "    print(\"Uyarı: GPU bulunamadı veya aktif değil. Model eğitimi CPU üzerinde daha yavaş olacaktır.\")\n",
        "    print(\"Colab'da GPU'yu aktifleştirmek için 'Runtime' -> 'Change runtime type' menüsünü kullanabilirsiniz.\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "9UpRa-Adk-cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 3: Ses Veri Setinin Yüklenmesi (SUPERB ks Örneği) ve Temel İnceleme (trust_remote_code ile Güncellenmiş)\n",
        "\n",
        "from datasets import load_dataset\n",
        "from IPython.display import Audio # Sesi not defterinde çalmak için\n",
        "import random # Rastgele örnek seçmek için\n",
        "\n",
        "# Örnek olarak SUPERB benchmark'ının Keyword Spotting (\"ks\") görevini kullanacağız.\n",
        "dataset_name = \"superb\"\n",
        "config_name = \"ks\" # Keyword Spotting\n",
        "\n",
        "print(f\"'{dataset_name}' veri setinin '{config_name}' yapılandırması yükleniyor (trust_remote_code=True)...\")\n",
        "try:\n",
        "    # dataset_raw'ı global yapalım ki sonraki hücrelerden erişilebilsin\n",
        "    global dataset_raw\n",
        "    dataset_raw = load_dataset(dataset_name, config_name, trust_remote_code=True) # <<-- trust_remote_code=True eklendi\n",
        "\n",
        "    print(f\"\\n'{dataset_name}' ({config_name}) veri seti başarıyla yüklendi.\")\n",
        "    print(\"\\nYüklenen Ham Veri Seti Yapısı:\")\n",
        "    print(dataset_raw)\n",
        "\n",
        "    available_splits = list(dataset_raw.keys())\n",
        "    if not available_splits:\n",
        "        raise ValueError(\"Veri setinde hiçbir alt küme (split) bulunamadı.\")\n",
        "\n",
        "    split_to_inspect = 'train' if 'train' in available_splits else available_splits[0]\n",
        "\n",
        "    print(f\"\\n'{split_to_inspect}' alt kümesinin özellikleri (features):\")\n",
        "    print(dataset_raw[split_to_inspect].features)\n",
        "\n",
        "    # Etiket bilgisini alalım (label_feature'ı global yapalım)\n",
        "    global label_feature\n",
        "    if 'label' in dataset_raw[split_to_inspect].features:\n",
        "        label_feature = dataset_raw[split_to_inspect].features['label']\n",
        "        print(f\"\\nEtiket Bilgisi ('label' özelliği):\")\n",
        "        print(label_feature)\n",
        "        if hasattr(label_feature, 'names'):\n",
        "            print(f\"Toplam etiket sayısı: {label_feature.num_classes}\")\n",
        "            print(f\"Etiket isimleri: {label_feature.names}\")\n",
        "        else:\n",
        "            print(\"Uyarı: 'label' özelliği bir ClassLabel değil gibi görünüyor veya 'names' attribute'u yok.\")\n",
        "    else:\n",
        "        print(\"Uyarı: Veri setinde 'label' özelliği bulunamadı.\")\n",
        "        label_feature = None\n",
        "\n",
        "    if split_to_inspect in dataset_raw and len(dataset_raw[split_to_inspect]) > 0:\n",
        "        print(f\"\\n'{split_to_inspect}' setinden rastgele bir ses örneği dinleniyor...\")\n",
        "        random_index = random.randint(0, len(dataset_raw[split_to_inspect]) - 1)\n",
        "        random_sample = dataset_raw[split_to_inspect][random_index]\n",
        "\n",
        "        # Ses verisi ve örnekleme oranını al\n",
        "        # 'audio' özelliğinin varlığını ve beklenen yapıda olduğunu kontrol et\n",
        "        if \"audio\" in random_sample and isinstance(random_sample[\"audio\"], dict) and \\\n",
        "           \"array\" in random_sample[\"audio\"] and \"sampling_rate\" in random_sample[\"audio\"]:\n",
        "\n",
        "            audio_data = random_sample[\"audio\"][\"array\"]\n",
        "            sampling_rate = random_sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "            print(f\"  Örnek ID: {random_sample.get('file', 'N/A') if isinstance(random_sample, dict) else random_index}\")\n",
        "            print(f\"  Örnekleme Oranı (Sampling Rate): {sampling_rate} Hz\")\n",
        "\n",
        "            if label_feature and 'label' in random_sample and hasattr(label_feature, 'int2str'):\n",
        "                label_id = random_sample[\"label\"]\n",
        "                print(f\"  Etiket ID: {label_id}, Etiket Adı: {label_feature.int2str(label_id)}\")\n",
        "            elif 'label' in random_sample:\n",
        "                 print(f\"  Etiket ID: {random_sample['label']}\")\n",
        "\n",
        "            display(Audio(data=audio_data, rate=sampling_rate))\n",
        "        else:\n",
        "            print(\"  Hata: Ses verisi veya örnekleme oranı seçilen örnekte beklenen formatta bulunamadı.\")\n",
        "            print(f\"  Örnek içeriği: {random_sample}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n'{split_to_inspect}' seti boş veya bulunamadı, örnek ses dinlenemiyor.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nVeri seti yüklenirken veya işlenirken bir hata oluştu: {e}\")\n",
        "    import traceback\n",
        "    print(traceback.format_exc())\n",
        "    if 'dataset_raw' in globals(): del dataset_raw # Hata durumunda değişkeni temizle\n",
        "    if 'label_feature' in globals(): del label_feature # Hata durumunda değişkeni temizle"
      ],
      "metadata": {
        "id": "5yMPxqLroAd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 4: Ses Veri Seti Ön İşleme (Wav2Vec2 için - Düzeltilmiş max_length ile)\n",
        "\n",
        "from transformers import AutoFeatureExtractor\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "# import librosa # Alternatif yeniden örnekleme için, gerekirse aktif edilebilir\n",
        "\n",
        "# dataset_raw ve label_feature'ın Hücre 3'te tanımlandığını varsayıyoruz.\n",
        "model_checkpoint_w2v2 = \"facebook/wav2vec2-base\"\n",
        "\n",
        "if 'dataset_raw' in globals() and dataset_raw is not None:\n",
        "    try:\n",
        "        print(f\"'{model_checkpoint_w2v2}' için Feature Extractor yükleniyor...\")\n",
        "        global feature_extractor # Diğer hücrelerde gerekebilir\n",
        "        feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint_w2v2)\n",
        "\n",
        "        target_sampling_rate = feature_extractor.sampling_rate\n",
        "        print(f\"Feature extractor başarıyla yüklendi. Hedef örnekleme hızı: {target_sampling_rate} Hz\")\n",
        "\n",
        "        # Ön işleme fonksiyonu\n",
        "        def preprocess_function(batch):\n",
        "            audio_arrays = []\n",
        "            for audio_item in batch[\"audio\"]:\n",
        "                speech_array = audio_item[\"array\"]\n",
        "                current_sampling_rate = audio_item[\"sampling_rate\"]\n",
        "\n",
        "                if current_sampling_rate != target_sampling_rate:\n",
        "                    speech_tensor = torch.tensor(speech_array).unsqueeze(0)\n",
        "                    resampler = T.Resample(orig_freq=current_sampling_rate, new_freq=target_sampling_rate)\n",
        "                    resampled_speech_tensor = resampler(speech_tensor)\n",
        "                    speech_array_processed = resampled_speech_tensor.squeeze(0).numpy()\n",
        "                else:\n",
        "                    speech_array_processed = speech_array\n",
        "\n",
        "                audio_arrays.append(speech_array_processed)\n",
        "\n",
        "            # Feature extractor'ı uygula - DÜZELTİLMİŞ KISIM\n",
        "            inputs = feature_extractor(\n",
        "                audio_arrays,\n",
        "                sampling_rate=target_sampling_rate,\n",
        "                padding=\"max_length\",    # <<<--- padding stratejisi max_length'e göre\n",
        "                max_length=16000,        # <<<--- max_length tanımlandı (1 saniye için 16000 sample)\n",
        "                truncation=True,         # <<<--- truncation şimdi max_length ile çalışacak\n",
        "                return_tensors=\"pt\"      # PyTorch tensörleri olarak döndür\n",
        "            )\n",
        "            return inputs\n",
        "\n",
        "        print(f\"\\nSes veri seti ön işleniyor (örnekleme hızı {target_sampling_rate} Hz'e ayarlanıyor, max_length=16000)...\")\n",
        "        print(\"Bu işlem veri setinin büyüklüğüne göre biraz zaman alabilir.\")\n",
        "\n",
        "        global encoded_dataset # Diğer hücrelerde gerekebilir\n",
        "        encoded_dataset = dataset_raw.map(\n",
        "            preprocess_function,\n",
        "            batched=True,\n",
        "            batch_size=100\n",
        "        )\n",
        "\n",
        "        print(f\"\\nMap sonrası '{list(encoded_dataset.keys())[0]}' alt kümesinin sütunları: {encoded_dataset[list(encoded_dataset.keys())[0]].column_names}\")\n",
        "\n",
        "        # Gereksiz sütunları kaldıralım ve sadece gerekli olanları tutalım\n",
        "        # 'input_values' ve 'attention_mask' feature extractor tarafından döndürülür. 'label' zaten var.\n",
        "        final_columns_to_keep = ['input_values', 'attention_mask', 'label']\n",
        "\n",
        "        # Her bir split için sütunları ayıkla\n",
        "        for split_name in encoded_dataset.keys():\n",
        "            current_columns = encoded_dataset[split_name].column_names\n",
        "            cols_to_remove_final = [col for col in current_columns if col not in final_columns_to_keep]\n",
        "            if cols_to_remove_final:\n",
        "                encoded_dataset[split_name] = encoded_dataset[split_name].remove_columns(cols_to_remove_final)\n",
        "\n",
        "        # set_format(\"torch\") zaten return_tensors=\"pt\" ile büyük ölçüde sağlanır,\n",
        "        # ancak DataLoader ile uyumluluk için yine de çağrılabilir.\n",
        "        # Eğer .map() zaten tensörler döndürüyorsa, bu satır bazen gereksiz olabilir veya\n",
        "        # Dataset objesinin iç yapısını değiştirebilir. Şimdilik teyit için bırakalım.\n",
        "        try:\n",
        "            encoded_dataset.set_format(\"torch\")\n",
        "        except Exception as e_set_format:\n",
        "            print(f\"set_format('torch') sırasında uyarı/hata (genellikle sorun değil): {e_set_format}\")\n",
        "\n",
        "\n",
        "        print(\"\\nSes veri seti başarıyla ön işlendi.\")\n",
        "        print(\"Ön işlenmiş veri seti yapısı:\")\n",
        "        print(encoded_dataset)\n",
        "\n",
        "        if list(encoded_dataset.keys()):\n",
        "            split_to_show = list(encoded_dataset.keys())[0]\n",
        "            if len(encoded_dataset[split_to_show]) > 0:\n",
        "                print(f\"\\nÖn işlenmiş '{split_to_show}' setinden ilk örnek:\")\n",
        "                example_processed = encoded_dataset[split_to_show][0]\n",
        "                print(f\"  Özellikler: {list(example_processed.keys())}\")\n",
        "                if 'input_values' in example_processed:\n",
        "                    print(f\"  input_values şekli: {example_processed['input_values'].shape}\")\n",
        "                if 'attention_mask' in example_processed:\n",
        "                    print(f\"  attention_mask şekli: {example_processed['attention_mask'].shape}\")\n",
        "                print(f\"  label: {example_processed['label']}\")\n",
        "            else:\n",
        "                print(f\"'{split_to_show}' seti boş.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFeature extractor yüklenirken veya ön işleme sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'feature_extractor' in globals(): del feature_extractor\n",
        "        if 'encoded_dataset' in globals(): del encoded_dataset\n",
        "else:\n",
        "    print(\"Hata: 'dataset_raw' bulunamadığı için ön işleme başlatılamadı.\")\n",
        "    if 'feature_extractor' in globals(): del feature_extractor\n",
        "    if 'encoded_dataset' in globals(): del encoded_dataset"
      ],
      "metadata": {
        "id": "9g154hs5qNTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 5: Wav2Vec2 Modelinin Yüklenmesi (Ses Sınıflandırması İçin)\n",
        "\n",
        "from transformers import AutoModelForAudioClassification\n",
        "\n",
        "# model_checkpoint_w2v2 Hücre 4'te tanımlanmıştı: \"facebook/wav2vec2-base\"\n",
        "# label_feature Hücre 3'te tanımlanmıştı ve sınıf sayısını içeriyordu.\n",
        "# device Hücre 2'de tanımlanmıştı.\n",
        "\n",
        "if 'model_checkpoint_w2v2' in globals() and \\\n",
        "   'label_feature' in globals() and label_feature is not None and hasattr(label_feature, 'num_classes') and \\\n",
        "   'device' in globals():\n",
        "\n",
        "    num_classes = label_feature.num_classes\n",
        "    print(f\"'{model_checkpoint_w2v2}' modeli '{num_classes}' etiket ile ses sınıflandırma görevi için yükleniyor...\")\n",
        "\n",
        "    try:\n",
        "        # model_w2v2'yi global yapalım\n",
        "        global model_w2v2\n",
        "        model_w2v2 = AutoModelForAudioClassification.from_pretrained(\n",
        "            model_checkpoint_w2v2,\n",
        "            num_labels=num_classes,\n",
        "            # Wav2Vec2, pooling modunu veya attention mask'in nasıl kullanılacağını belirten\n",
        "            # bazı ek config parametreleri alabilir. Şimdilik varsayılanları kullanalım.\n",
        "            # Eğer feature extractor 'attention_mask' döndürmediyse ve model bunu bekliyorsa,\n",
        "            # config'de `m.config.apply_spec_augment = False` veya `m.config.mask_time_prob = 0` gibi ayarlar gerekebilir\n",
        "            # ya da feature extractor'ın attention_mask döndürmesi sağlanabilir.\n",
        "            # Şimdilik en basit haliyle yükleyelim.\n",
        "            # ignore_mismatched_sizes=True, eğer önceden eğitilmiş başlık varsa ve bizim num_labels ile uyuşmuyorsa\n",
        "            # yeniden başlatmayı zorlar. num_labels verdiğimizde bu genellikle otomatik yönetilir.\n",
        "        )\n",
        "\n",
        "        model_w2v2.to(device) # Modeli tanımlanan cihaza (GPU/CPU) taşı\n",
        "\n",
        "        print(f\"\\nModel başarıyla yüklendi ve '{device}' cihazına taşındı.\")\n",
        "\n",
        "        total_params = sum(p.numel() for p in model_w2v2.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model_w2v2.parameters() if p.requires_grad)\n",
        "        print(f\"\\nModeldeki toplam parametre sayısı: {total_params:,}\")\n",
        "        print(f\"Modeldeki eğitilebilir parametre sayısı: {trainable_params:,}\")\n",
        "\n",
        "        # Modelin ve sınıflandırıcısının doğru sayıda etiket için yapılandırıldığını doğrula\n",
        "        if hasattr(model_w2v2.config, 'num_labels'):\n",
        "            print(f\"Modelin yapılandırmasındaki etiket sayısı: {model_w2v2.config.num_labels}\")\n",
        "        # AutoModelForAudioClassification genellikle bir 'classifier' katmanına sahiptir.\n",
        "        # Wav2Vec2ForSequenceClassification için bu katmanın adı 'classifier'dır.\n",
        "        # Eğer farklı bir isimdeyse (örn: projection_head, head vb.), ona göre kontrol edin.\n",
        "        # Genellikle son linear katmanın out_features'ı num_labels olmalıdır.\n",
        "        # Wav2Vec2ForSequenceClassification'da bu model.classifier.out_features'dır.\n",
        "        if hasattr(model_w2v2, 'classifier') and hasattr(model_w2v2.classifier, 'out_features'):\n",
        "             print(f\"Sınıflandırıcı katmanının ('classifier') çıktı boyutu: {model_w2v2.classifier.out_features}\")\n",
        "        elif hasattr(model_w2v2, 'projector') and hasattr(model_w2v2.projector, 'out_features'): # Bazen 'projector' olabilir\n",
        "             print(f\"Sınıflandırıcı katmanının ('projector') çıktı boyutu: {model_w2v2.projector.out_features}\")\n",
        "        else:\n",
        "            # Son katmanı bulmaya çalışalım (genellikle en son nn.Linear)\n",
        "            final_layer = None\n",
        "            for _, module in reversed(list(model_w2v2.named_modules())):\n",
        "                if isinstance(module, torch.nn.Linear):\n",
        "                    final_layer = module\n",
        "                    break\n",
        "            if final_layer is not None:\n",
        "                print(f\"Modelin son Linear katmanının çıktı boyutu: {final_layer.out_features}\")\n",
        "            else:\n",
        "                print(\"Sınıflandırıcı katmanının çıktı boyutu otomatik olarak tespit edilemedi, ancak num_labels doğru ayarlanmış olmalı.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nModel yüklenirken bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'model_w2v2' in globals(): del model_w2v2\n",
        "else:\n",
        "    print(\"Hata: Gerekli değişkenler ('model_checkpoint_w2v2', 'label_feature', 'device') bulunamadı.\")\n",
        "    if 'model_w2v2' in globals(): del model_w2v2"
      ],
      "metadata": {
        "id": "qBbB3SVdqQhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 6: Eğitim Argümanları, Metrikler ve Wav2Vec2 Modelinin Eğitilmesi\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "# numpy, torch, time zaten Hücre 2'de import edilmişti.\n",
        "# model_w2v2, encoded_dataset, feature_extractor, device değişkenlerinin\n",
        "# önceki hücrelerde doğru şekilde tanımlandığını ve erişilebilir olduğunu varsayıyoruz.\n",
        "# label_feature da Hücre 3'ten gelmeli (sınıf sayısı ve isimleri için).\n",
        "\n",
        "# 1. Performans Metriklerini Hesaplama Fonksiyonu (Ses Sınıflandırması İçin)\n",
        "def compute_metrics_audio(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Çok sınıflı durum için 'macro' veya 'weighted' ortalama kullanılabilir.\n",
        "    # 'macro' her sınıfı eşit kabul eder, 'weighted' sınıf büyüklüğüne göre ağırlar.\n",
        "    # Proje isterlerinde genel bir F1 beklentisi var, 'macro' F1 genellikle iyi bir metriktir.\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Specificity (Çok Sınıflı Durumda):\n",
        "    # Her sınıf için One-vs-Rest mantığıyla TN/(TN+FP) hesaplayıp ortalamasını alabiliriz.\n",
        "    # Ya da makro ortalamalı bir karmaşıklık matrisinden türetebiliriz.\n",
        "    # Şimdilik, her sınıf için ayrı ayrı hesaplayıp ortalamasını alalım.\n",
        "    num_classes_for_metrics = label_feature.num_classes if 'label_feature' in globals() and label_feature else 12 # Fallback\n",
        "    conf_matrix = confusion_matrix(labels, preds, labels=list(range(num_classes_for_metrics)))\n",
        "    per_class_specificity = []\n",
        "    for i in range(num_classes_for_metrics):\n",
        "        tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i,:]) + np.sum(conf_matrix[:,i]) - conf_matrix[i,i])\n",
        "        fp = np.sum(conf_matrix[:,i]) - conf_matrix[i,i]\n",
        "        if (tn + fp) > 0:\n",
        "            per_class_specificity.append(tn / (tn + fp))\n",
        "        else:\n",
        "            per_class_specificity.append(0.0)\n",
        "    specificity_macro = np.mean(per_class_specificity) if per_class_specificity else 0.0\n",
        "\n",
        "    # AUC (Çok Sınıflı Durumda):\n",
        "    # One-vs-Rest (OvR) veya One-vs-One (OvO) stratejisiyle, genellikle 'macro' ortalamalı.\n",
        "    auc_macro = 0.0\n",
        "    if pred.predictions.ndim == 2 and pred.predictions.shape[1] == num_classes_for_metrics:\n",
        "        try:\n",
        "            logits_tensor = torch.tensor(pred.predictions)\n",
        "            probs = torch.softmax(logits_tensor, dim=-1).cpu().numpy()\n",
        "            # multi_class='ovr' (one-vs-rest) veya 'ovo' (one-vs-one)\n",
        "            # average='macro' veya 'weighted'\n",
        "            auc_macro = roc_auc_score(labels, probs, multi_class='ovr', average='macro')\n",
        "        except ValueError as e: # Örneğin, bir sınıfa ait hiç örnek yoksa veya tek bir sınıf varsa\n",
        "            # print(f\"AUC (macro) hesaplanırken uyarı: {e}\")\n",
        "            auc_macro = 0.0\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro, # Sensitivity (macro)\n",
        "        'f1_macro': f1_macro,\n",
        "        'specificity_macro': specificity_macro,\n",
        "        'auc_macro': auc_macro\n",
        "    }\n",
        "\n",
        "# 2. Eğitim Argümanları (TrainingArguments)\n",
        "# Ses modelleri daha fazla VRAM tüketebilir, batch size'ı dikkatli ayarlayın.\n",
        "training_args_w2v2 = TrainingArguments(\n",
        "    output_dir=\"./wav2vec2_ks_results\",      # Yeni bir çıktı dizini\n",
        "    num_train_epochs=5,                      # Ses modelleri için biraz daha fazla epoch denenebilir (örn: 5-10)\n",
        "    per_device_train_batch_size=8,           # Daha küçük batch size (VRAM'a göre)\n",
        "    per_device_eval_batch_size=16,          # Değerlendirme için de\n",
        "    learning_rate=3e-5,                      # Wav2Vec2 için yaygın bir öğrenme oranı\n",
        "    warmup_ratio=0.1,                        # Isınma adımı oranı\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",        # Çok sınıflı için F1-macro iyi bir metriktir\n",
        "    save_total_limit=2,\n",
        "    report_to=\"tensorboard\",\n",
        "    # remove_unused_columns=False, # Eğer .map() sonrası gereksiz sütunlar kaldıysa ve Trainer hata veriyorsa True yapın\n",
        "                                   # Ancak Hücre 4'te sütunları temizlemiştik.\n",
        "    # fp16=torch.cuda.is_available(), # Karışık hassasiyetli eğitimi deneyebilirsiniz\n",
        ")\n",
        "\n",
        "print(f\"\\nEğitim argümanları (Wav2Vec2 için) tanımlandı. Çıktı dizini: {training_args_w2v2.output_dir}\")\n",
        "\n",
        "# 3. Trainer Objesinin Oluşturulması\n",
        "# Gerekli değişkenlerin varlığını kontrol edelim\n",
        "if 'model_w2v2' in globals() and model_w2v2 is not None and \\\n",
        "   'encoded_dataset' in globals() and encoded_dataset is not None and \\\n",
        "   'feature_extractor' in globals() and feature_extractor is not None and \\\n",
        "   'device' in globals() : # training_time burada henüz yok\n",
        "\n",
        "    # trainer_w2v2'yi global yapalım\n",
        "    global trainer_w2v2\n",
        "    trainer_w2v2 = Trainer(\n",
        "        model=model_w2v2,\n",
        "        args=training_args_w2v2,\n",
        "        train_dataset=encoded_dataset[\"train\"],\n",
        "        eval_dataset=encoded_dataset[\"validation\"],\n",
        "        tokenizer=feature_extractor, # Ses modelleri için tokenizer yerine feature_extractor verilir\n",
        "        compute_metrics=compute_metrics_audio\n",
        "    )\n",
        "    print(\"\\nTrainer objesi (Wav2Vec2 için) başarıyla oluşturuldu.\")\n",
        "\n",
        "    print(\"\\nWav2Vec2 modeli eğitimi başlatılıyor...\")\n",
        "    print(f\"Kullanılan cihaz: {device}. Epoch: {training_args_w2v2.num_train_epochs}, Train Batch: {training_args_w2v2.per_device_train_batch_size}\")\n",
        "\n",
        "    # training_time_w2v2'yi global yapalım\n",
        "    global training_time_w2v2\n",
        "    start_time_w2v2_train = time.time()\n",
        "    try:\n",
        "        train_result_w2v2 = trainer_w2v2.train()\n",
        "        end_time_w2v2_train = time.time()\n",
        "        training_time_w2v2 = end_time_w2v2_train - start_time_w2v2_train\n",
        "\n",
        "        print(f\"\\nEğitim tamamlandı! Toplam eğitim süresi: {training_time_w2v2:.2f} saniye ({training_time_w2v2/60:.2f} dakika).\")\n",
        "\n",
        "        if hasattr(train_result_w2v2, 'metrics') and train_result_w2v2.metrics:\n",
        "            print(\"Genel eğitim sonuç metrikleri (trainer.train() dönüşünden):\")\n",
        "            for key, value in train_result_w2v2.metrics.items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        best_model_path_w2v2 = f\"{training_args_w2v2.output_dir}/best_model\"\n",
        "        trainer_w2v2.save_model(best_model_path_w2v2)\n",
        "        # Feature extractor'ı da kaydetmek iyi bir pratiktir\n",
        "        feature_extractor.save_pretrained(best_model_path_w2v2)\n",
        "        print(f\"Eğitim sonrası (en iyi) Wav2Vec2 modeli ve feature extractor '{best_model_path_w2v2}' adresine kaydedildi.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nWav2Vec2 modeli eğitimi sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'train_result_w2v2' not in globals(): train_result_w2v2 = None\n",
        "        training_time_w2v2 = None\n",
        "else:\n",
        "    print(\"\\nModel, işlenmiş veri seti veya feature extractor bulunamadığı için Trainer oluşturulamadı ve eğitim başlatılamadı.\")\n",
        "    if 'trainer_w2v2' in globals(): del trainer_w2v2\n",
        "    if 'train_result_w2v2' not in globals(): train_result_w2v2 = None\n",
        "    training_time_w2v2 = None"
      ],
      "metadata": {
        "id": "bE2QjG9MvpBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 7 (Wav2Vec2): Eğitilmiş Modelin Test Seti Üzerinde Değerlendirilmesi\n",
        "\n",
        "print(\"Eğitilmiş Wav2Vec2 modeli test seti üzerinde değerlendiriliyor...\")\n",
        "\n",
        "# trainer_w2v2 ve encoded_dataset'in önceki hücrelerden doğru geldiğini varsayıyoruz.\n",
        "if 'trainer_w2v2' in globals() and trainer_w2v2 is not None and \\\n",
        "   'encoded_dataset' in globals() and \"test\" in encoded_dataset:\n",
        "    try:\n",
        "        # Değerlendirilecek veri setini belirtiyoruz (test seti)\n",
        "        # trainer_w2v2.model zaten en iyi modeli içermeli (load_best_model_at_end=True sayesinde)\n",
        "        test_metrics_w2v2_output = trainer_w2v2.evaluate(eval_dataset=encoded_dataset[\"test\"])\n",
        "\n",
        "        print(\"\\nWav2Vec2 Test Seti Performans Metrikleri:\")\n",
        "        # Trainer evaluate metodu, metrik isimlerinin başına 'eval_' ekler.\n",
        "        print(f\"  Test Kaybı (Loss): {test_metrics_w2v2_output.get('eval_loss', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Accuracy: {test_metrics_w2v2_output.get('eval_accuracy', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Precision (Macro): {test_metrics_w2v2_output.get('eval_precision_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Recall (Macro): {test_metrics_w2v2_output.get('eval_recall_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test F1-Score (Macro): {test_metrics_w2v2_output.get('eval_f1_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Specificity (Macro): {test_metrics_w2v2_output.get('eval_specificity_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test AUC (Macro): {test_metrics_w2v2_output.get('eval_auc_macro', 'N/A'):.4f}\") # Burası yine 0.0 gelebilir\n",
        "\n",
        "        # Metrikleri daha sonra kullanmak üzere saklayalım\n",
        "        global wav2vec2_test_metrics\n",
        "        wav2vec2_test_metrics = test_metrics_w2v2_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTest seti değerlendirmesi sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        wav2vec2_test_metrics = None\n",
        "else:\n",
        "    print(\"Hata: 'trainer_w2v2' objesi veya 'encoded_dataset['test']' bulunamadı.\")\n",
        "    print(\"Lütfen önceki hücrelerin doğru çalıştığından emin olun.\")\n",
        "    wav2vec2_test_metrics = None"
      ],
      "metadata": {
        "id": "uwijUr4T9Yqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 8 (Wav2Vec2): Karmaşıklık Matrisi ve ROC Eğrisinin Çizdirilmesi\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay\n",
        "# sklearn.metrics.auc zaten Hücre 7'de compute_metrics_audio içinde roc_auc_score olarak kullanıldı.\n",
        "# Burada RocCurveDisplay'i de kullanabiliriz.\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import label_binarize # Çok sınıflı ROC için\n",
        "\n",
        "# Gerekli değişkenlerin (trainer_w2v2, encoded_dataset, wav2vec2_test_metrics, label_feature)\n",
        "# önceki hücrelerden doğru geldiğini varsayıyoruz.\n",
        "if 'trainer_w2v2' in globals() and trainer_w2v2 is not None and \\\n",
        "   'encoded_dataset' in globals() and \"test\" in encoded_dataset and \\\n",
        "   'wav2vec2_test_metrics' in globals() and wav2vec2_test_metrics is not None and \\\n",
        "   'label_feature' in globals() and label_feature is not None and hasattr(label_feature, 'names'):\n",
        "\n",
        "    print(\"Test seti üzerinde tahminler (logitler ve olasılıklar) alınıyor...\")\n",
        "    try:\n",
        "        test_predictions_output = trainer_w2v2.predict(encoded_dataset[\"test\"])\n",
        "\n",
        "        logits = test_predictions_output.predictions\n",
        "        probabilities = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
        "        predicted_labels = np.argmax(logits, axis=1)\n",
        "        true_labels = test_predictions_output.label_ids\n",
        "\n",
        "        num_classes = label_feature.num_classes\n",
        "        class_names = label_feature.names\n",
        "\n",
        "        # 1. Karmaşıklık Matrisi (Confusion Matrix)\n",
        "        cm = confusion_matrix(true_labels, predicted_labels, labels=list(range(num_classes)))\n",
        "\n",
        "        plt.figure(figsize=(10, 8)) # Matris daha büyük olacağı için boyutu ayarlayalım\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                    xticklabels=class_names,\n",
        "                    yticklabels=class_names)\n",
        "        plt.title('Karmaşıklık Matrisi (Wav2Vec2 - Test Seti)')\n",
        "        plt.xlabel('Tahmin Edilen Etiket')\n",
        "        plt.ylabel('Gerçek Etiket')\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout() # Etiketlerin sıkışmasını önlemek için\n",
        "        plt.show()\n",
        "\n",
        "        # TN, FP, FN, TP değerlerini çok sınıflı durumda her sınıf için veya genel olarak vermek yerine,\n",
        "        # karmaşıklık matrisinin kendisi ana bilgiyi verir.\n",
        "        # İstenirse her sınıf için bu değerler ayrıca hesaplanabilir.\n",
        "\n",
        "        # 2. ROC Eğrisi ve AUC (Çok Sınıflı Durum - Macro Average)\n",
        "        # Gerçek etiketleri binarize et (one-hot encoding gibi)\n",
        "        y_true_binarized = label_binarize(true_labels, classes=list(range(num_classes)))\n",
        "\n",
        "        # Her sınıf için ROC eğrisi çizdirme ve makro-ortalama AUC hesaplama\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "\n",
        "        for i in range(num_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], probabilities[:, i])\n",
        "            roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Makro-ortalama ROC Eğrisi\n",
        "        # Öncelikle tüm fpr değerlerini birleştirelim (interpolasyon gerekli olabilir)\n",
        "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "        # Sonra her bir ROC eğrisini bu noktalara göre interpolasyon yapalım\n",
        "        mean_tpr = np.zeros_like(all_fpr)\n",
        "        for i in range(num_classes):\n",
        "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "        # Ortalamasını alalım\n",
        "        mean_tpr /= num_classes\n",
        "        roc_auc_macro_manual = sklearn.metrics.auc(all_fpr, mean_tpr)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(all_fpr, mean_tpr,\n",
        "                 label=f'Makro-Ortalama ROC eğrisi (AUC = {roc_auc_macro_manual:.4f})',\n",
        "                 color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "        # Her sınıf için ROC eğrisini de çizdirebiliriz (isteğe bağlı, grafik kalabalıklaşabilir)\n",
        "        # from itertools import cycle\n",
        "        # colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan', 'magenta'])\n",
        "        # for i, color in zip(range(num_classes), colors):\n",
        "        #     plt.plot(fpr[i], tpr[i], color=color, lw=1.5, alpha=0.7,\n",
        "        #              label=f'ROC Sınıf {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=2) # Rastgele tahmin çizgisi\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('Yanlış Pozitif Oranı (False Positive Rate)')\n",
        "        plt.ylabel('Doğru Pozitif Oranı (True Positive Rate)')\n",
        "        plt.title('Çok Sınıflı Alıcı İşletim Karakteristiği (ROC) Eğrisi - Makro Ortalama')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nHücre 7'de hesaplanan Test AUC (Macro) (trainer.evaluate): {wav2vec2_test_metrics.get('eval_auc_macro', 'N/A'):.4f}\")\n",
        "        print(f\"Bu hücrede Makro-Ortalama ROC için hesaplanan AUC (sklearn): {roc_auc_macro_manual:.4f}\")\n",
        "        print(\"Not: İki AUC değerinin yakın olması beklenir. Farklılıklar, sklearn'deki roc_auc_score'un 'ovr' stratejisi ile\")\n",
        "        print(\"burada çizilen manuel makro-ortalama ROC eğrisi arasındaki hesaplama detaylarından kaynaklanabilir.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTahminler alınırken veya görselleştirmeler oluşturulurken bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "else:\n",
        "    print(\"Hata: Gerekli değişkenler ('trainer_w2v2', 'encoded_dataset['test']', 'wav2vec2_test_metrics', 'label_feature') bulunamadı.\")\n",
        "    print(\"Lütfen önceki hücrelerin doğru çalıştığından emin olun.\")"
      ],
      "metadata": {
        "id": "9qnjqSDU9_bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 9 (Wav2Vec2): Eğitim ve Doğrulama Kayıp/Metrik Grafikleri\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# trainer_w2v2 ve log_history'nin Hücre 6'dan geldiğini varsayıyoruz\n",
        "if 'trainer_w2v2' in globals() and trainer_w2v2 is not None and \\\n",
        "   hasattr(trainer_w2v2.state, 'log_history') and trainer_w2v2.state.log_history:\n",
        "\n",
        "    log_history_w2v2 = trainer_w2v2.state.log_history\n",
        "\n",
        "    print(\"Wav2Vec2 Ham log_history içeriği (ilk 3 ve son 3 kayıt - eğer yeterliyse):\")\n",
        "    num_entries_to_show = 3\n",
        "    if len(log_history_w2v2) > 2 * num_entries_to_show:\n",
        "        for i in range(num_entries_to_show): print(log_history_w2v2[i])\n",
        "        print(\"...\")\n",
        "        for i in range(len(log_history_w2v2) - num_entries_to_show, len(log_history_w2v2)): print(log_history_w2v2[i])\n",
        "    else:\n",
        "        for entry in log_history_w2v2: print(entry)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    log_df_w2v2 = pd.DataFrame(log_history_w2v2)\n",
        "\n",
        "    # Eğitim logları (sadece 'loss' içeren ve 'eval_loss' içermeyenler)\n",
        "    train_logs_df_w2v2 = log_df_w2v2[log_df_w2v2['loss'].notna() & log_df_w2v2['eval_loss'].isna()].copy()\n",
        "\n",
        "    # Değerlendirme logları ('eval_loss' içerenler)\n",
        "    eval_logs_df_w2v2 = log_df_w2v2[log_df_w2v2['eval_loss'].notna()].copy()\n",
        "\n",
        "    # Grafikleri çizdirelim\n",
        "    if not train_logs_df_w2v2.empty and not eval_logs_df_w2v2.empty:\n",
        "        # --- Kayıp Grafiği ---\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_logs_df_w2v2['epoch'], train_logs_df_w2v2['loss'], 'b-o', label='Eğitim Kaybı (Training Loss)')\n",
        "        plt.plot(eval_logs_df_w2v2['epoch'], eval_logs_df_w2v2['eval_loss'], 'r-s', label='Doğrulama Kaybı (Validation Loss)')\n",
        "        plt.title('Wav2Vec2: Epoch Bazında Eğitim ve Doğrulama Kaybı')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Kayıp (Loss)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        epochs_present = sorted(list(set(eval_logs_df_w2v2['epoch'].round().tolist())))\n",
        "        if epochs_present:\n",
        "            min_e, max_e = min(epochs_present), max(epochs_present)\n",
        "            plt.xticks(np.arange(int(min_e), int(max_e) + 1, 1.0))\n",
        "            plt.xlim(left=int(min_e) - 0.5 if int(min_e) > 0 else 0, right=int(max_e) + 0.5)\n",
        "        plt.show()\n",
        "\n",
        "        # --- Doğruluk ve F1 Macro Grafiği ---\n",
        "        fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        # Sol y-ekseni (Doğruluk)\n",
        "        color = 'tab:green'\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Doğruluk (Accuracy)', color=color)\n",
        "        ax1.plot(eval_logs_df_w2v2['epoch'], eval_logs_df_w2v2['eval_accuracy'], color=color, marker='^', linestyle='-', label='Doğrulama Doğruluğu')\n",
        "        ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "        # Sağ y-ekseni (F1 Macro)\n",
        "        ax2 = ax1.twinx() # Aynı x-eksenini paylaşan ikinci bir y-ekseni\n",
        "        color = 'tab:purple'\n",
        "        ax2.set_ylabel('F1 Skoru (Macro)', color=color)\n",
        "        ax2.plot(eval_logs_df_w2v2['epoch'], eval_logs_df_w2v2['eval_f1_macro'], color=color, marker='x', linestyle='--', label='Doğrulama F1 (Macro)')\n",
        "        ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "        plt.title('Wav2Vec2: Epoch Bazında Doğrulama Metrikleri (Accuracy & F1 Macro)')\n",
        "        fig.tight_layout() # Etiketlerin üst üste binmemesi için\n",
        "        # Lejantları birleştirmek için:\n",
        "        lines, labels = ax1.get_legend_handles_labels()\n",
        "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "        ax2.legend(lines + lines2, labels + labels2, loc='best')\n",
        "\n",
        "        if epochs_present: # Aynı x-ekseni ayarını kullanalım\n",
        "            plt.xticks(np.arange(int(min_e), int(max_e) + 1, 1.0))\n",
        "            ax1.set_xlim(left=int(min_e) - 0.5 if int(min_e) > 0 else 0, right=int(max_e) + 0.5)\n",
        "\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"Grafik çizdirmek için yeterli eğitim veya doğrulama logu bulunamadı.\")\n",
        "        if train_logs_df_w2v2.empty: print(\"Eğitim logları filtrelenemedi.\")\n",
        "        if eval_logs_df_w2v2.empty: print(\"Doğrulama logları filtrelenemedi.\")\n",
        "else:\n",
        "    print(\"Hata: 'trainer_w2v2' objesi veya 'log_history' bulunamadı.\")"
      ],
      "metadata": {
        "id": "cjeVf5nk-kDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 10 (Wav2Vec2): Eğitim ve Çıkarım Sürelerinin Hesaplanması\n",
        "\n",
        "# time, torch, tqdm.auto, DataLoader zaten import edilmiş olmalı (Hücre 2'den veya önceki hücrelerden)\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Eğitim Süresi\n",
        "calculated_training_time_w2v2 = None\n",
        "if 'training_time_w2v2' in globals() and training_time_w2v2 is not None: # Hücre 6'da global yapılmıştı\n",
        "    calculated_training_time_w2v2 = training_time_w2v2\n",
        "elif 'trainer_w2v2' in globals() and trainer_w2v2 is not None and \\\n",
        "     hasattr(trainer_w2v2.state, 'log_history') and trainer_w2v2.state.log_history:\n",
        "    for log_entry in reversed(trainer_w2v2.state.log_history):\n",
        "        if 'train_runtime' in log_entry:\n",
        "            calculated_training_time_w2v2 = log_entry['train_runtime']\n",
        "            break\n",
        "\n",
        "if calculated_training_time_w2v2 is not None:\n",
        "    print(f\"Toplam Wav2Vec2 Model Eğitim Süresi: {calculated_training_time_w2v2:.2f} saniye ({calculated_training_time_w2v2/60:.2f} dakika)\")\n",
        "else:\n",
        "    print(\"Wav2Vec2 eğitim süresi bilgisi `training_time_w2v2` değişkeninden veya `log_history`'den alınamadı.\")\n",
        "\n",
        "# 2. Örnek Başına Ortalama Çıkarım Süresi (Test Seti Üzerinden)\n",
        "avg_inference_time_per_sample_w2v2 = None\n",
        "# Gerekli değişkenlerin varlığını kontrol edelim\n",
        "if 'model_w2v2' in globals() and model_w2v2 is not None and \\\n",
        "   'encoded_dataset' in globals() and \"test\" in encoded_dataset and \\\n",
        "   'device' in globals() and 'feature_extractor' in globals() and feature_extractor is not None :\n",
        "\n",
        "    model_w2v2.eval() # Modeli değerlendirme moduna al\n",
        "\n",
        "    # Modelin beklediği giriş sütunlarını belirle\n",
        "    # Wav2Vec2FeatureExtractor genellikle 'input_values' ve 'attention_mask' (eğer padding varsa) döndürür\n",
        "    model_input_names_w2v2 = []\n",
        "    if 'input_values' in encoded_dataset[\"test\"].features:\n",
        "        model_input_names_w2v2.append('input_values')\n",
        "    if 'attention_mask' in encoded_dataset[\"test\"].features: # Hücre 4'te attention_mask eklenmemişti\n",
        "        model_input_names_w2v2.append('attention_mask')\n",
        "\n",
        "    if not model_input_names_w2v2: # Eğer hiçbir şey bulamazsak, varsayılanı kullanalım\n",
        "         model_input_names_w2v2 = ['input_values']\n",
        "         print(f\"Uyarı: Model giriş sütunları otomatik algılanamadı, varsayılan kullanılıyor: {model_input_names_w2v2}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Sadece modelin ihtiyaç duyduğu sütunları içeren bir test seti kopyası oluştur\n",
        "        inference_ready_dataset_w2v2 = encoded_dataset[\"test\"].select_columns(model_input_names_w2v2)\n",
        "        inference_ready_dataset_w2v2.set_format(\"torch\")\n",
        "    except Exception as e_cols:\n",
        "        print(f\"Uyarı: Çıkarım için sütun seçimi/formatlamada sorun ({e_cols}). Orijinal test seti kullanılacak.\")\n",
        "        inference_ready_dataset_w2v2 = encoded_dataset[\"test\"]\n",
        "\n",
        "\n",
        "    inference_batch_size_w2v2 = training_args_w2v2.per_device_eval_batch_size if 'training_args_w2v2' in globals() else 16\n",
        "    inference_dataloader_w2v2 = DataLoader(inference_ready_dataset_w2v2, batch_size=inference_batch_size_w2v2)\n",
        "\n",
        "    total_inference_time_val_w2v2 = 0.0\n",
        "    num_samples_processed_w2v2 = 0\n",
        "\n",
        "    print(f\"\\nWav2Vec2 Test seti üzerinde çıkarım süresi hesaplanıyor (Batch Size: {inference_batch_size_w2v2})...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(inference_dataloader_w2v2, desc=\"Wav2Vec2 Çıkarım\"):\n",
        "            inputs_for_model = {}\n",
        "            valid_batch = True\n",
        "            for name in model_input_names_w2v2:\n",
        "                if name in batch:\n",
        "                    inputs_for_model[name] = batch[name].to(device)\n",
        "                else:\n",
        "                    if name == 'input_values': valid_batch = False\n",
        "                    break\n",
        "\n",
        "            if not valid_batch or not inputs_for_model :\n",
        "                try: num_in_batch = len(batch.get(model_input_names_w2v2[0], [])) if batch and model_input_names_w2v2 else 0\n",
        "                except: num_in_batch = 0\n",
        "                if num_in_batch > 0 : print(f\"Uyarı: Geçerli model girdisi eksik, {num_in_batch} örnek içeren bu yığın atlandı.\")\n",
        "                continue\n",
        "\n",
        "            current_batch_size = len(inputs_for_model[model_input_names_w2v2[0]]) # İlk ana girdi sütununun boyutu\n",
        "            num_samples_processed_w2v2 += current_batch_size\n",
        "\n",
        "            start_batch_time = time.perf_counter()\n",
        "            outputs = model_w2v2(**inputs_for_model)\n",
        "            end_batch_time = time.perf_counter()\n",
        "\n",
        "            batch_time = end_batch_time - start_batch_time\n",
        "            total_inference_time_val_w2v2 += batch_time\n",
        "\n",
        "    if num_samples_processed_w2v2 > 0 and total_inference_time_val_w2v2 > 0 :\n",
        "        avg_inference_time_per_sample_w2v2 = total_inference_time_val_w2v2 / num_samples_processed_w2v2\n",
        "        samples_per_second_inference_w2v2 = num_samples_processed_w2v2 / total_inference_time_val_w2v2\n",
        "        print(f\"\\nToplam {num_samples_processed_w2v2} örnek için Wav2Vec2 çıkarım süresi: {total_inference_time_val_w2v2:.4f} saniye\")\n",
        "        print(f\"Örnek başına ortalama Wav2Vec2 çıkarım süresi: {avg_inference_time_per_sample_w2v2:.6f} saniye/örnek\")\n",
        "        print(f\"Saniyede işlenen Wav2Vec2 örnek sayısı (çıkarım): {samples_per_second_inference_w2v2:.2f} örnek/saniye\")\n",
        "    elif num_samples_processed_w2v2 > 0 and total_inference_time_val_w2v2 == 0 :\n",
        "        print(f\"\\nToplam {num_samples_processed_w2v2} örnek için Wav2Vec2 çıkarım süresi çok kısa, hız çok yüksek.\")\n",
        "        avg_inference_time_per_sample_w2v2 = 0.0\n",
        "    else:\n",
        "        print(\"Wav2Vec2 Çıkarım için hiç örnek işlenemedi veya süre ölçülemedi.\")\n",
        "\n",
        "else:\n",
        "    print(\"Hata: Wav2Vec2 Modeli, işlenmiş test seti, feature extractor veya cihaz bilgisi bulunamadı.\")"
      ],
      "metadata": {
        "id": "FYT2vhwJ-8mh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}