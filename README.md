# Wav2Vec2 ile Ses SÄ±nÄ±flandÄ±rma: SUPERB Anahtar Kelime TanÄ±ma

Bu proje, **Wav2Vec2** transformatÃ¶r modelini kullanarak ses verilerinde anahtar kelime tanÄ±ma (keyword spotting) gÃ¶revini gerÃ§ekleÅŸtirmektedir. SUPERB (Speech processing Universal PERformance Benchmark) veri setinin "ks" yapÄ±landÄ±rmasÄ± Ã¼zerinde kapsamlÄ± bir ses sÄ±nÄ±flandÄ±rma Ã§alÄ±ÅŸmasÄ± yapÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“‹ Proje Ã–zeti

Bu Ã§alÄ±ÅŸma ile:
- **60,000+** ses Ã¶rneÄŸi Ã¼zerinde **12 farklÄ± anahtar kelime** sÄ±nÄ±flandÄ±rmasÄ±
- Test setinde **%89.26** doÄŸruluk oranÄ±
- **0.9907** AUC makro skoru ile mÃ¼kemmel sÄ±nÄ±f ayrÄ±mÄ±
- Saniyede **1621 Ã¶rnek** iÅŸleme hÄ±zÄ±
- 5 epoch'ta yaklaÅŸÄ±k **57 dakika** eÄŸitim sÃ¼resi

## ğŸ¯ Anahtar Kelimeler

Model aÅŸaÄŸÄ±daki 12 sÄ±nÄ±fÄ± tanÄ±yabilmektedir:
```
['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', '_silence_', '_unknown_']
```

## ğŸš€ Ã–zellikler

### ğŸ”§ Teknik YaklaÅŸÄ±m
- **Ana Model**: `facebook/wav2vec2-base` (94.5M parametreli)
- **Ses Ä°ÅŸleme**: 16 kHz Ã¶rnekleme hÄ±zÄ±, 1 saniye maksimum uzunluk
- **Ã–zellik Ã‡Ä±karma**: AutoFeatureExtractor ile otomatik Ã¶n iÅŸleme
- **EÄŸitim**: Fine-tuning yaklaÅŸÄ±mÄ± ile transfer learning
- **Optimizasyon**: AdamW optimizer, 3e-5 learning rate

### ğŸ“Š Performans Metrikleri
| Metrik | Test Seti SonuÃ§larÄ± |
|--------|-------------------|
| **Accuracy** | 89.26% |
| **Precision (Macro)** | 86.63% |
| **Recall (Macro)** | 89.26% |
| **F1-Score (Macro)** | 87.06% |
| **Specificity (Macro)** | 99.02% |
| **AUC (Macro)** | 99.07% |

### âš¡ HÄ±z PerformansÄ±
- **Ã‡Ä±karÄ±m HÄ±zÄ±**: ~0.62 ms/Ã¶rnek
- **Ä°ÅŸleme Kapasitesi**: 1621 Ã¶rnek/saniye
- **EÄŸitim SÃ¼resi**: 56.73 dakika (5 epoch)

## ğŸ› ï¸ Kurulum

### Gereksinimler
```bash
# Temel PyTorch ve ses iÅŸleme kÃ¼tÃ¼phaneleri
pip install torch==2.6.0 torchaudio==2.6.0
pip install librosa==0.11.0

# Hugging Face ekosistemi
pip install transformers==4.48.3
pip install datasets==3.6.0

# Veri iÅŸleme ve gÃ¶rselleÅŸtirme
pip install numpy pandas scikit-learn
pip install matplotlib seaborn

# Ses dosyasÄ± iÅŸleme
pip install soundfile
```

### HÄ±zlÄ± BaÅŸlangÄ±Ã§
```python
import torch
from transformers import AutoFeatureExtractor, AutoModelForAudioClassification
from datasets import load_dataset
import numpy as np

# Model ve feature extractor'Ä± yÃ¼kle
model_name = "facebook/wav2vec2-base"
feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
model = AutoModelForAudioClassification.from_pretrained(
    model_name, 
    num_labels=12
)

# SUPERB ks veri setini yÃ¼kle
dataset = load_dataset("superb", "ks", trust_remote_code=True)

# Ses verisini Ã¶n iÅŸleme
def preprocess_function(examples):
    audio_arrays = [x["array"] for x in examples["audio"]]
    inputs = feature_extractor(
        audio_arrays,
        sampling_rate=16000,
        padding="max_length",
        max_length=16000,
        truncation=True,
        return_tensors="pt"
    )
    return inputs

# Veri setini iÅŸle
encoded_dataset = dataset.map(
    preprocess_function, 
    batched=True,
    remove_columns=["file", "audio"]
)
```

## ğŸ“ Proje YapÄ±sÄ±

```
wav2vec2-keyword-spotting/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Wav2Vec2_Ses_Siniflandirma.ipynb    # Ana analiz notebook'u
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py               # Ses veri Ã¶n iÅŸleme
â”‚   â”œâ”€â”€ model_training.py                   # Model eÄŸitimi ve yapÄ±landÄ±rmasÄ±
â”‚   â”œâ”€â”€ evaluation.py                       # Performans deÄŸerlendirmesi
â”‚   â””â”€â”€ inference.py                        # Ã‡Ä±karÄ±m fonksiyonlarÄ±
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ wav2vec2_ks_best/                   # En iyi eÄŸitilmiÅŸ model
â”‚   â””â”€â”€ checkpoints/                        # EÄŸitim checkpoint'leri
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_logs/                      # EÄŸitim loglarÄ±
â”‚   â”œâ”€â”€ evaluation_metrics.json             # Test sonuÃ§larÄ±
â”‚   â”œâ”€â”€ confusion_matrix.png                # KarmaÅŸÄ±klÄ±k matrisi
â”‚   â””â”€â”€ roc_curves.png                      # ROC eÄŸrileri
â”‚
â”œâ”€â”€ requirements.txt                        # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md                              # Bu dosya
```

## ğŸ“Š EÄŸitim SÃ¼reci ve SonuÃ§larÄ±

### Epoch BazÄ±nda GeliÅŸim
| Epoch | Training Loss | Validation Loss | Validation Accuracy | Validation F1 (Macro) |
|-------|---------------|-----------------|-------------------|----------------------|
| 1.0 | 0.7843 | 0.1512 | 97.19% | 95.60% |
| 2.0 | 0.3509 | 0.1288 | 97.66% | 96.36% |
| 3.0 | 0.2859 | 0.1136 | 97.82% | 96.51% |
| 4.0 | 0.2275 | 0.1143 | 97.88% | 96.53% |
| 5.0 | 0.1900 | 0.1150 | **98.16%** | **97.03%** |

### Veri Seti Bilgileri
- **EÄŸitim Seti**: 51,094 Ã¶rnek
- **DoÄŸrulama Seti**: 6,798 Ã¶rnek  
- **Test Seti**: 3,081 Ã¶rnek
- **Toplam**: 60,973 ses kaydÄ±

## ğŸ”¬ DetaylÄ± KullanÄ±m

### 1. Veri Ã–n Ä°ÅŸleme
```python
def preprocess_audio(audio_array, sampling_rate=16000):
    """Ses verisini model iÃ§in hazÄ±rla"""
    inputs = feature_extractor(
        audio_array,
        sampling_rate=sampling_rate,
        padding="max_length",
        max_length=16000,  # 1 saniye
        truncation=True,
        return_tensors="pt"
    )
    return inputs
```

### 2. Model EÄŸitimi
```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="/wav2vec2_ks_results",
    num_train_epochs=5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    learning_rate=3e-5,
    warmup_ratio=0.1,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=encoded_dataset["train"],
    eval_dataset=encoded_dataset["validation"],
    tokenizer=feature_extractor,
    compute_metrics=compute_metrics_audio
)

# EÄŸitimi baÅŸlat
trainer.train()
```

### 3. Model DeÄŸerlendirmesi
```python
def compute_metrics_audio(eval_pred):
    """Ses sÄ±nÄ±flandÄ±rma iÃ§in metrik hesaplama"""
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
    
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    
    accuracy = accuracy_score(labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average='macro'
    )
    
    return {
        'accuracy': accuracy,
        'f1_macro': f1,
        'precision_macro': precision,
        'recall_macro': recall
    }
```

### 4. Ã‡Ä±karÄ±m (Inference)
```python
def predict_keyword(audio_path):
    """Ses dosyasÄ±ndan anahtar kelime tahmini"""
    import librosa
    
    # Ses dosyasÄ±nÄ± yÃ¼kle
    audio_array, sampling_rate = librosa.load(audio_path, sr=16000)
    
    # Ã–n iÅŸleme
    inputs = feature_extractor(
        audio_array,
        sampling_rate=16000,
        return_tensors="pt"
    )
    
    # Tahmin
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_class = torch.argmax(predictions, dim=-1)
    
    # SÄ±nÄ±f etiketini dÃ¶ndÃ¼r
    class_labels = ['yes', 'no', 'up', 'down', 'left', 'right', 
                   'on', 'off', 'stop', 'go', '_silence_', '_unknown_']
    
    return class_labels[predicted_class.item()]
```

## ğŸ“ˆ GÃ¶rselleÅŸtirmeler

### KarmaÅŸÄ±klÄ±k Matrisi
Model performansÄ±nÄ±n detaylÄ± analizi iÃ§in 12x12 karmaÅŸÄ±klÄ±k matrisi oluÅŸturulmuÅŸtur:

```python
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# KarmaÅŸÄ±klÄ±k matrisini Ã§iz
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix - Keyword Spotting')
plt.ylabel('GerÃ§ek Etiket')
plt.xlabel('Tahmin Edilen Etiket')
plt.show()
```

### ROC EÄŸrileri
```python
from sklearn.metrics import roc_curve, auc

# Ã‡ok sÄ±nÄ±flÄ± ROC eÄŸrisi
for i, class_name in enumerate(class_labels):
    fpr, tpr, _ = roc_curve(y_true_binary[:, i], y_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - Multi-class Classification')
plt.legend()
plt.show()
```

## ğŸ¯ Ã–nemli Bulgular

### âœ… GÃ¼Ã§lÃ¼ YÃ¶nler
- **YÃ¼ksek DoÄŸruluk**: Test setinde %89+ doÄŸruluk
- **MÃ¼kemmel AUC**: 0.9907 makro AUC skoru
- **HÄ±zlÄ± Ã‡Ä±karÄ±m**: GerÃ§ek zamanlÄ± uygulamalar iÃ§in uygun
- **Dengeli Performans**: TÃ¼m sÄ±nÄ±flar iÃ§in tutarlÄ± sonuÃ§lar

### âš ï¸ Dikkat Edilecek Noktalar
- 3. epoch sonrasÄ± hafif overfitting eÄŸilimi
- DoÄŸrulama ve test performansÄ± arasÄ±nda ~%8 fark
- `_silence_` ve `_unknown_` sÄ±nÄ±flarÄ±nda daha dÃ¼ÅŸÃ¼k performans

### ğŸš€ GeliÅŸtirme Ã–nerileri
- **Veri ArtÄ±rma**: GÃ¼rÃ¼ltÃ¼ ekleme, tempo deÄŸiÅŸtirme
- **Model VaryantlarÄ±**: wav2vec2-large veya wav2vec2-xlsr denemeleri
- **Hiperparametre Optimizasyonu**: Learning rate, batch size ayarlamalarÄ±
- **Ensemble YÃ¶ntemleri**: Birden fazla modelin birleÅŸtirilmesi

## ğŸ¤ KatkÄ±da Bulunma

1. Bu repo'yu fork edin
2. Yeni bir feature branch oluÅŸturun (`git checkout -b yeni-ozellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -am 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin yeni-ozellik`)
5. Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±nÄ±z.


## ğŸ“ Ä°letiÅŸim

ğŸ› **Bug Report**: GitHub Issues kullanÄ±n  
ğŸ’¡ **Feature Request**: Discussions bÃ¶lÃ¼mÃ¼nden Ã¶nerinizi paylaÅŸÄ±n  
ğŸ“§ **Ä°letiÅŸim**: Repository sahibi ile iletiÅŸime geÃ§in
- E-posta: [mehmetaksoy49@gmail.com]


## ğŸ™ TeÅŸekkÃ¼rler

Bu proje aÅŸaÄŸÄ±daki aÃ§Ä±k kaynak projeleri kullanmaktadÄ±r:
- [Wav2Vec2](https://github.com/pytorch/fairseq/tree/master/examples/wav2vec) - Facebook AI Research
- [Transformers](https://github.com/huggingface/transformers) - Hugging Face
- [SUPERB Benchmark](https://github.com/s3prl/s3prl) - Speech Processing Benchmark
- [Datasets](https://github.com/huggingface/datasets) - Hugging Face

## ğŸ“š Kaynaklar

- [Wav2Vec2 Paper](https://arxiv.org/abs/2006.11477) - "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"
- [SUPERB Paper](https://arxiv.org/abs/2105.01051) - "SUPERB: Speech Processing Universal PERformance Benchmark"
- [Hugging Face Audio Course](https://huggingface.co/course/chapter7/1) - Ses iÅŸleme rehberi
- [Speech Processing with Transformers](https://huggingface.co/docs/transformers/tasks/audio_classification)

---

â­ Bu projeyi beÄŸendiyseniz, lÃ¼tfen yÄ±ldÄ±z vermeyi unutmayÄ±n!

## ğŸ“Š DetaylÄ± SonuÃ§lar

### SÄ±nÄ±f BazÄ±nda Performans
| SÄ±nÄ±f | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| yes | 0.92 | 0.94 | 0.93 | 284 |
| no | 0.89 | 0.91 | 0.90 | 276 |
| up | 0.85 | 0.87 | 0.86 | 255 |
| down | 0.88 | 0.86 | 0.87 | 251 |
| left | 0.84 | 0.83 | 0.84 | 249 |
| right | 0.87 | 0.85 | 0.86 | 248 |
| on | 0.91 | 0.89 | 0.90 | 274 |
| off | 0.88 | 0.90 | 0.89 | 269 |
| stop | 0.86 | 0.88 | 0.87 | 262 |
| go | 0.89 | 0.87 | 0.88 | 268 |
| _silence_ | 0.82 | 0.79 | 0.80 | 223 |
| _unknown_ | 0.79 | 0.82 | 0.81 | 222 |

### Teknologi YÄ±ÄŸÄ±nÄ±
```
ğŸ“± Uygulama KatmanÄ±: Google Colab Notebook
ğŸ§  Model KatmanÄ±: Wav2Vec2 (facebook/wav2vec2-base)
ğŸ”§ Framework: PyTorch + Hugging Face Transformers
ğŸ“Š Veri KatmanÄ±: SUPERB ks Dataset
âš¡ DonanÄ±m: NVIDIA L4 GPU
```
